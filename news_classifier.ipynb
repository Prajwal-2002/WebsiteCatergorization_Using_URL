{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ut0tAsAwvfTr"
      },
      "outputs": [],
      "source": [
        "\n",
        "from keras.datasets import imdb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.layers import LSTM, Activation, Dropout, Dense, Input, MaxPooling1D, Conv1D, GlobalMaxPooling1D\n",
        "from keras.layers import Embedding\n",
        "from keras.models import Model\n",
        "import string\n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGWzA_aOMvsS",
        "outputId": "afc3411e-d15a-4baa-9973-37bb2913f238"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following packages will be REMOVED:\n",
            "  libcudnn8-dev\n",
            "The following held packages will be changed:\n",
            "  libcudnn8\n",
            "The following packages will be DOWNGRADED:\n",
            "  libcudnn8\n",
            "0 upgraded, 0 newly installed, 1 downgraded, 1 to remove and 3 not upgraded.\n",
            "Need to get 430 MB of archives.\n",
            "After this operation, 1,392 MB disk space will be freed.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n",
            "Fetched 430 MB in 9s (48.2 MB/s)\n",
            "(Reading database ... 123991 files and directories currently installed.)\n",
            "Removing libcudnn8-dev (8.1.1.33-1+cuda11.2) ...\n",
            "update-alternatives: removing manually selected alternative - switching libcudnn to auto mode\n",
            "\u001b[1mdpkg:\u001b[0m \u001b[1;33mwarning:\u001b[0m downgrading libcudnn8 from 8.1.1.33-1+cuda11.2 to 8.1.0.77-1+cuda11.2\n",
            "(Reading database ... 123968 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.1.1.33-1+cuda11.2) ...\n",
            "Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('refined_ds_news2.csv')\n",
        "df = data[['cleaned_data']].copy()"
      ],
      "metadata": {
        "id": "_6gSYInywRcT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_data = []\n",
        "for i in range(df.shape[0]):\n",
        "  cleaned_data.append(df.cleaned_data.values[0])\n",
        " \n",
        "sentiment = data['Category']"
      ],
      "metadata": {
        "id": "hZuLX9fcxcJc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array(list(map(lambda x: 1 if x==\"news liberal\" else 0, sentiment)))\n",
        "\n",
        "X_train, X_test,Y_train, Y_test = train_test_split(cleaned_data, y, test_size=0.2, random_state = 45)"
      ],
      "metadata": {
        "id": "fdTdFAEnyC3u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "words_to_index = tokenizer.word_index"
      ],
      "metadata": {
        "id": "VxZzrQPcyaxk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(words_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcJz_vcbHMuy",
        "outputId": "47bc42e1-aabc-434f-8f8f-fd9a4aa76c52"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'trump': 1, 'view': 2, 'follow': 3, 'political': 4, 'story': 5, 'flynn': 6, 'gop': 7, 'right': 8, 'late': 9, 'perspective': 10, 'email': 11, 'american': 12, 'hay': 13, 'editor': 14, 'george': 15, 'president': 16, 'spectacle': 17, 'spectator': 18, 'news': 19, 'contact': 20, 'blog': 21, 'letter': 22, 'files': 23, 'neumayr': 24, 'prescription': 25, 'read': 26, 'receive': 27, 'foundation': 28, 'midterm': 29, 'david': 30, 'life': 31, 'time': 32, 'go': 33, 'thanksgiving': 34, 'scott': 35, 'mckay': 36, 'hither': 37, 'yon': 38, 'run': 39, 'party': 40, 'report': 41, 'culture': 42, 'democrats': 43, 'daily': 44, 'folios': 45, 'consecutive': 46, 'policy': 47, 'government': 48, 'special': 49, 'authors': 50, 'submissions': 51, 'magazine': 52, 'itxu': 53, 'd√≠az': 54, 'memoriam': 55, 'night': 56, 'daniel': 57, 'john': 58, 'support': 59, 'election': 60, 'editors': 61, 'obituary': 62, 'premature': 63, 'thankful': 64, 'god': 65, 'turkeys': 66, 'true': 67, 'indians': 68, 'paul': 69, 'kengor': 70, 'francis': 71, 'quick': 72, 'things': 73, 'edition': 74, 'georgia': 75, 'majority': 76, 'yes': 77, 'donald': 78, 'campaign': 79, 'virtue': 80, 'sign': 81, 'politic': 82, 'update': 83, 'desantis': 84, 'ep': 85, 'usa': 86, 'public': 87, 'new': 88, 'favor': 89, 'traditional': 90, 'featured': 91, 'month': 92, 'subscribe': 93, 'shop': 94, 'donate': 95, 'author': 96, 'governors': 97, 'conference': 98, 'show': 99, 'learn': 100, 'todd': 101, 'carney': 102, 'man': 103, 'agent': 104, 'provocateur': 105, 'lucianne': 106, 'goldberg': 107, 'rick': 108, 'marschall': 109, 'juul': 110, 'struggle': 111, 'fda': 112, 'illuminate': 113, 'larger': 114, 'trend': 115, 'abuse': 116, 'mcgarry': 117, 'art': 118, 'imitate': 119, 'arthur': 120, 'miller': 121, 'realism': 122, 'stand': 123, 'test': 124, 'leonora': 125, 'cravotta': 126, 'goodbye': 127, 'science': 128, 'hello': 129, 'max': 130, 'dublin': 131, 'james': 132, 'dobson': 133, 'cause': 134, 'colorado': 135, 'springs': 136, 'tragedy': 137, 'labor': 138, 'prevent': 139, 'letters': 140, 'elton': 141, 'scores': 142, 'career': 143, 'capping': 144, 'grand': 145, 'slam': 146, 'final': 147, 'performance': 148, 'deroy': 149, 'murdock': 150, 'federally': 151, 'hour': 152, 'day': 153, 'picks': 154, 'missionary': 155, 'ridge': 156, 'generational': 157, 'courage': 158, 'sempa': 159, 'poof': 160, 'california': 161, 'surplus': 162, 'steven': 163, 'greenhut': 164, 'muslim': 165, 'comintern': 166, 'roger': 167, 'kaplan': 168, 'warnock': 169, 'catron': 170, 'republicans': 171, 'house': 172, 'senate': 173, 'know': 174, 'announce': 175, 'jeffrey': 176, 'lord': 177, 'democratic': 178, 'sunday': 179, 'feel': 180, 'duty': 181, 'prev': 182, 'register': 183, 'talkie': 184, 'quiet': 185, 'audience': 186, 'bruce': 187, 'bawer': 188, 'cultural': 189, 'america': 190, 'death': 191, 'qatar': 192, 'choose': 193, 'state': 194, 'sentences': 195, 'real': 196, 'work': 197, 'sentence': 198, 'americana': 199, 'bad': 200, 'service': 201, 'constant': 202, 'consent': 203, 'politicsthe': 204, 'educate': 205, 'idea': 206, 'concept': 207, 'value': 208, 'economic': 209, 'freedom': 210, 'individual': 211, 'liberty': 212, 'self': 213, 'sufficiency': 214, 'limited': 215, 'black': 216, 'friday': 217, 'login': 218, 'logout': 219, 'edit': 220, 'account': 221, 'menu': 222, 'hot': 223, 'press': 224, 'laughing': 225, 'matter': 226, 'free': 227, 'market': 228, 'politically': 229, 'correct': 230, 'buy': 231, 'book': 232, 'arts': 233, 'popular': 234, 'judge': 235, 'rewrite': 236, 'law': 237, 'eke': 238, 'representatives': 239, 'mystery': 240, 'remain': 241, 'send': 242, 'incumbent': 243, 'raphael': 244, 'convince': 245, 'voter': 246, 'reelect': 247, 'care': 248, 'nominee': 249, 'tuesday': 250, 'anybody': 251, 'want': 252, 'talk': 253, 'squirrel': 254, 'shiny': 255, 'object': 256, 'useless': 257, 'lot': 258, 'national': 259, 'review': 260, 'friend': 261, 'piece': 262, 'simply': 263, 'title': 264, 'photo': 265, 'week': 266, 'respectfully': 267, 'response': 268, 'announcement': 269, 'stupid': 270, 'get': 271, 'stupider': 272, 'victory': 273, 'thousand': 274, 'father': 275, 'defeat': 276, 'orphan': 277, 'observe': 278, 'kennedy': 279, 'certainly': 280, 'responsible': 281, 'malaise': 282, 'far': 283, 'suffer': 284, 'ostracism': 285, 'irreligious': 286, 'signal': 287, 'elder': 288, 'introduce': 289, 'young': 290, 'education': 291, 'nontraditional': 292, 'modern': 293, 'adult': 294, 'expose': 295, 'child': 296, 'vice': 297, 'look': 298, 'moral': 299, 'rot': 300, 'school': 301, 'newsletter': 302, 'sure': 303, 'informed': 304, 'general': 305, 'favorite': 306, 'draw': 307, 'humor': 308, 'decline': 309, 'help': 310, 'dems': 311, 'impose': 312, 'gay': 313, 'marriage': 314, 'pope': 315, 'protect': 316, 'graft': 317, 'ridden': 318, 'cardinals': 319, 'depravity': 320, 'wish': 321, 'learning': 322, 'disability': 323, 'voters': 324, 'decide': 325, 'roll': 326, 'seniorscare': 327, 'program': 328, 'whistle': 329, 'past': 330, 'graveyard': 331, 'merrick': 332, 'garland': 333, 'insurrection': 334, 'establishment': 335, 'myth': 336, 'dry': 337, 'world': 338, 'cup': 339, 'mess': 340, 'lol': 341, 'asa': 342, 'hutchinson': 343, 'covid': 344, 'amnesty': 345, 'end': 346, 'nigh': 347, 'usual': 348, 'wrong': 349, 'melissa': 350, 'mackenzie': 351, 'stories': 352, 'crawlers': 353, 'congress': 354, 'prediction': 355, 'join': 356, 'fun': 357, 'catastrophic': 358, 'debate': 359, 'nominating': 360, 'republican': 361, 'percent': 362, 'irony': 363, 'liberals': 364, 'wishes': 365, 'pro': 366, 'lifers': 367, 'hallow': 368, 'halloween': 369, 'answer': 370, 'mass': 371, 'shooting': 372, 'whodunit': 373, 'nancy': 374, 'pelosi': 375, 'lack': 376, 'basic': 377, 'skill': 378, 'great': 379, 'legislators': 380, 'trumpers': 381, 'pence': 382, 'tries': 383, 'distance': 384, 'fauci': 385, 'chosen': 386, 'tv': 387, 'series': 388, 'christ': 389, 'pleases': 390, 'protestants': 391, 'catholics': 392, 'alike': 393, 'portrayal': 394, 'virgin': 395, 'mary': 396, 'ellie': 397, 'gardey': 398, 'falling': 399, 'rising': 400, 'watch': 401, 'kathy': 402, 'hochul': 403, 'smug': 404, 'touch': 405, 'lee': 406, 'zeldin': 407, 'york': 408, 'governor': 409, 'hidden': 410, 'silver': 411, 'linings': 412, 'midterms': 413, 'hard': 414, 'begin': 415, 'dov': 416, 'fischer': 417, 'threat': 418, 'democracy': 419, 'herschel': 420, 'walker': 421, 'redemption': 422, 'conservative': 423, 'change': 424, 'deep': 425, 'elegy': 426, 'fbi': 427, 'loom': 428, 'trial': 429, 'conviction': 430, 'parry': 431, 'vladimir': 432, 'zelenko': 433, 'joe': 434, 'biden': 435, 'energy': 436, 'jihad': 437, 'politics': 438, 'classical': 439, 'schools': 440, 'promote': 441, 'ideal': 442, 'entrepreneurship': 443, 'winston': 444, 'brady': 445, 'venezuelan': 446, 'grateful': 447, 'capitalism': 448, 'jorge': 449, 'galicia': 450, 'give': 451, 'thank': 452, 'low': 453, 'skilled': 454, 'workers': 455, 'veronique': 456, 'de': 457, 'rugy': 458, 'way': 459, 'cook': 460, 'turkey': 461, 'good': 462, 'tom': 463, 'raabe': 464, 'nonprofit': 465, 'effective': 466, 'charities': 467, 'fact': 468, 'fear': 469, 'table': 470, 'pounder': 471, 'win': 472, 'larry': 473, 'thornberry': 474, 'terms': 475, 'cookie': 476, 'privacy': 477, 'require': 478, 'select': 479, 'active': 480, 'subscribers': 481, 'example': 482, 'like': 483, 'unsubscribe': 484, 'anytime': 485, 'use': 486, 'leave': 487, 'field': 488, 'blank': 489, 'submit': 490, 'form': 491, 'marketing': 492, 's': 493, 'royal': 494, 'street': 495, 'alexandria': 496, 'va': 497, 'revoke': 498, 'safeunsubscribe': 499, 'link': 500, 'find': 501, 'deal': 502, 'offer': 503, 'renew': 504, 'year': 505, 'regular': 506, 'price': 507, 'monthly': 508}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_glove_vector(glove_vec):\n",
        "  with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
        "    words = set()\n",
        "    word_to_vec_map = {}\n",
        "    for line in f:\n",
        "      w_line = line.split()\n",
        "      curr_word = w_line[0]\n",
        "      word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
        "\n",
        "\n",
        "\n",
        "  return word_to_vec_map"
      ],
      "metadata": {
        "id": "dLgegtHtykQr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_vec_map = read_glove_vector('glove.6B.50d.txt')\n",
        "\n",
        "maxLen = 10000"
      ],
      "metadata": {
        "id": "1OBYP0L3yws8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len = len(words_to_index)+1\n",
        "embed_vector_len = word_to_vec_map['moon'].shape[0]\n",
        "\n",
        "emb_matrix = np.zeros((vocab_len, embed_vector_len))\n",
        "print(emb_matrix.shape)\n",
        "for word, index in words_to_index.items():\n",
        "  embedding_vector = word_to_vec_map.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    emb_matrix[index, :] = embedding_vector\n",
        "\n",
        "embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=maxLen, weights = [emb_matrix], trainable=False)\n"
      ],
      "metadata": {
        "id": "380fJ_ngzUTd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4818d762-646e-45c7-c4fd-1aeeac4e333e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(509, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsvdmKr3CKsz",
        "outputId": "ffca9595-aca5-415d-cacd-622c25f97d99"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(509, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def news_classify(input_shape):\n",
        "\n",
        "  X_indices = Input(input_shape)\n",
        "\n",
        "  embeddings = embedding_layer(X_indices)\n",
        "\n",
        "  X = LSTM(128, return_sequences=True)(embeddings)\n",
        "\n",
        "  X = Dropout(0.6)(X)\n",
        "\n",
        "  X = LSTM(128, return_sequences=True)(X)\n",
        "\n",
        "  X = Dropout(0.6)(X)\n",
        "\n",
        "  X = LSTM(128)(X)\n",
        "\n",
        "  X = Dense(1, activation='sigmoid')(X)\n",
        "\n",
        "  model = Model(inputs=X_indices, outputs=X)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "DfDmJpl28E9T"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv1d_model(input_shape):\n",
        "\n",
        "  X_indices = Input(input_shape)\n",
        "\n",
        "  embeddings = embedding_layer(X_indices)\n",
        "\n",
        "  X = Conv1D(512,3,activation='relu')(embeddings)\n",
        "  \n",
        "  X = MaxPooling1D(3)(X)\n",
        "\n",
        "  X = Conv1D(256,3,activation='relu')(X)\n",
        "  \n",
        "  X = MaxPooling1D(3)(X)\n",
        "\n",
        "  X = Conv1D(256,3,activation='relu')(X)\n",
        "  X = Dropout(0.8)(X)\n",
        "  X = MaxPooling1D(3)(X)\n",
        "\n",
        "  X = GlobalMaxPooling1D()(X)\n",
        "\n",
        "  X = Dense(256, activation='relu')(X)\n",
        "  X = Dense(1, activation='sigmoid')(X)\n",
        "\n",
        "  model = Model(inputs=X_indices, outputs=X)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "_sgjOXzx-D_S"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = news_classify((maxLen,))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1m7m_r8-Y3A",
        "outputId": "8e3518ec-c69a-49b1-8b9d-b2d2f542c070"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 10000)]           0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 10000, 50)         25450     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 10000, 128)        91648     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 10000, 128)        0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 10000, 128)        131584    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 10000, 128)        0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 380,395\n",
            "Trainable params: 354,945\n",
            "Non-trainable params: 25,450\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_indices = tokenizer.texts_to_sequences(X_train)\n",
        "X_train_indices = pad_sequences(X_train_indices, maxlen=maxLen, padding='post')"
      ],
      "metadata": {
        "id": "NER58k2B-zhC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_indices.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMJVsOcM8hLT",
        "outputId": "474093bd-a4a5-4f04-d982-0d75e61d8246"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adam = keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "90DRjvkp8zJK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "batch_size = 64\n",
        "history = model.fit(X_train_indices, Y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRFPi1Mn_JAz",
        "outputId": "345078bf-30e7-44ca-a0bd-9f84b8d992f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 158s 46s/step - loss: 0.6930 - accuracy: 0.7083 - val_loss: 0.6925 - val_accuracy: 0.6250\n",
            "Epoch 2/10\n"
          ]
        }
      ]
    }
  ]
}